# Документация — compress

Данная документация описывает установку, запуск, сборку и дальнейшую доработку проекта `compress` — простого суммаризатора текста на Python.

## Обзор

`compress` — минималистичный инструмент для извлечения ключевых предложений из русского текста с использованием частотного метода. Скрипт демонстрирует базовую логику: очистка текста, токенизация, удаление стоп-слов, подсчёт частоты слов, оценка предложений и выбор наиболее значимых.

## Быстрая установка

1. Клонируйте репозиторий:

```bash
git clone https://github.com/arduinoev3/compress.git
cd compress
```

2. Убедитесь, что установлен Python 3.6+.

## Использование

1. Поместите текст для анализа в переменную `text` в `compress.py` или модифицируйте скрипт для чтения из файла `text.txt` (в репозитории есть пример `text.txt`).

2. Запустите:

```bash
python3 compress.py
```

3. В результате в stdout будут выведены 3 наиболее релевантных предложения.

## Предложенные улучшения (план доработок)

- Вынести стоп-слова в отдельный файл и загружать их динамически (`stop_words_russian.txt` уже присутствует).
- Добавить аргументы командной строки (argparse): входной файл, количество предложений, пороги длины предложения.
- Добавить модульные тесты (pytest).
- Улучшить предобработку (лемматизация через pymorphy2 или spaCy, нормализация, очистка пунктуации).
- Заменить чисто частотный подход на TF-IDF или TextRank для более качественной суммаризации.

## Формирование сборки / упаковка

Проект — автономный скрипт, поэтому "сборка" как таковая не требуется. Для упаковки в pip-пакет или Docker-образ предложены следующие шаги:

- pip-пакет: создать `setup.py`/`pyproject.toml`, вынести логику в модуль, добавить entry-point.
- Docker: создать `Dockerfile`, использовать официальный образ python:3.11-slim, копировать файлы и запускать `python compress.py`.

## Переменные окружения и конфигурация

На уровне примера переменные окружения не используются. При расширении проекта стоит поддержать следующее:

- `COMPRESS_TOP_N` — число предложений в суммаризации
- `COMPRESS_STOPWORDS_PATH` — путь к файлу стоп-слов
- `COMPRESS_MIN_WORDS`, `COMPRESS_MAX_WORDS` — фильтры по длине предложения

## Тестирование

Добавьте `tests/` с unit-тестами для функций:

- `tokenize(text)`
- `load_stopwords(path)`
- `compute_word_frequencies(tokens, stopwords)`
- `score_sentences(sentences, word_freqs, min_words, max_words)`

Пример запуска (после добавления pytest):

```bash
pytest -q
```

## Структура проекта

- `compress.py` — основной скрипт
- `text.txt` — пример текста
- `stop_words_russian.txt` — файл со стоп-словами
- `docs/README.md` — эта документация
- `LICENSE` — MIT License

## Частые ошибки и замечания

- Убедитесь, что файл с текстом в кодировке UTF-8.
- Текущий код требует доработки, так как переменная `text` в `compress.py` не инициализирована корректно (есть `text = re.re`).

*** Конец документации ***
